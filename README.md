# ğŸ›’ Automated E-Commerce ETL Pipeline  

## ğŸ“Œ Project Overview  
This project demonstrates a modern **end-to-end data engineering pipeline** built with:  

- âœ… **Python** â€” for generating dummy e-commerce data (customers, orders, shipments).  
- âœ… **Snowflake** â€” as the cloud data warehouse.  
- âœ… **dbt** â€” for transformations (raw â†’ analytics).  
- âœ… **Apache Airflow** â€” for orchestration and scheduling.  

The pipeline simulates an **E-commerce order monitoring system**, taking raw data through ingestion, transformation, and analytics-ready modeling.  

---

## ğŸ—ï¸ Architecture  
1. **Data Generation**: Python scripts create synthetic e-commerce datasets (CSV format).  
2. **Raw Layer**: Data is loaded into a `raw` schema in Snowflake.  
3. **Transformations**: dbt models clean, join, and structure the data into fact & dimension tables.  
4. **Analytics Layer**: Results are materialized into an `analytics` schema.  
5. **Orchestration**: Airflow DAG schedules the pipeline.  

---

## âš™ï¸ Tech Stack  
- **Language**: Python 3.9  
- **Warehouse**: Snowflake  
- **Transformations**: dbt  
- **Orchestration**: Apache Airflow  
- **Version Control**: GitHub  

---

## ğŸš€ Setup & Installation  

### 1ï¸âƒ£ Clone the Repository  
```bash
git clone https://github.com/NdukaClara/automated-ecommerce-etl-pipeline.git
cd automated-ecommerce-etl-pipeline
